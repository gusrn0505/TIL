{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a368458",
   "metadata": {},
   "source": [
    "# Feature Extraction - t-SNE \n",
    "\n",
    "#### 참고 - https://woosikyang.github.io/first-post.html\n",
    "\n",
    "1. 적절한 이웃 반경 설정하기 - 원하는 수준의 엔트로피에 맞춰서\n",
    "- $x_i$ 는 원래 차원에서 가우시안 분포에 따라 분포한다 했을 때, 표준편차의 크기에 따라 $x_j$ 를 유의미한 이웃으로 고려할 수도 아닐 수도 있음\n",
    "  \n",
    "  - <=> radius(=표준편차)에 $p_{j|i}$ 값과 엔트로피는 비례한다\n",
    "- 따라서 우리가 원하는 엔트로피 정도에 따라 반경(radius)를 계산한다.\n",
    "\n",
    "\n",
    "2. 저차원 표현에 대한 비용 함수 - Kullback Leiber divergence - 설정하여, gradient 값 구하기 \n",
    "\n",
    "3. $y_i$에 대한 gradient 값을 기반으로 gradient descent 방법을 통해 y값 근접시키기. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dfd7143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 사용 및 라이브러리 설치 \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import heapq\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from collections import defaultdict\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston.data \n",
    "y = boston.target\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa8730",
   "metadata": {},
   "source": [
    "### 1. 적절한 이웃 반경 설정하기 \n",
    "\n",
    "**구현해야하는 것** \n",
    "- $p_{j|i}$ : 원래 차원(D)에서 객체 i가 j를 이웃으로 선택할 확률\n",
    "> $\\frac{e^{-\\frac{||x_i - x_j||^2}{2 \\sigma_i^2}}}{\\sum_{k \\neq i} e^{-\\frac{||x_i - x_j||^2}{2 \\sigma_i^2}}}$\n",
    "\n",
    "- $p_{ij}$ : $\\frac{p_{i|j} + p_{j|i}}{2n}$\n",
    "\n",
    "- $q_{j|i}$ : 축소된 차원(d)에서 객체 i가 j를 이웃으로 선택할 확율 \n",
    "> $\\frac{(1+ ||y_i - y_j||^2)^{-1}}{\\sum_{k \\neq i}(1+ ||y_i - y_j||^2)^{-1}}$\n",
    "\n",
    "- $h(P_i)$ : 엔트로피. \n",
    "> $\\sum p_{j|i}\\log_2 p_{i|j}$ \n",
    "\n",
    "- $per(P_i)$ : 복잡도. \n",
    "> $2^{h(P_i)}$ \n",
    "\n",
    "- 적정한 $\\sigma_i$ 값을 찾는 함수 \n",
    "\n",
    "\n",
    "**필요한 것**\n",
    "- X : 입력 데이터 \n",
    "- y : 랜덤한 데이터\n",
    "- n : 샘플 개수 \n",
    "\n",
    "**함수의 형태**\n",
    "- def __init__(self, X,s)  \n",
    "\n",
    "- def softmax(self, vector) :=>  softmax 값을 가진 list\n",
    "\n",
    "- def find_sigma(self, matrix, target_per) : => 적정한 sigma list\n",
    "> 필요한 것 : binary_search \n",
    "- def binary_search(self,fn, target, tol=1e-10, max_iter=10000, lower=1e-20, upper=1000.):\n",
    "> 필요한 것 : fn = per 함수\n",
    "\n",
    "- def per(self, vector, s) : =>  $per(P_i)$\n",
    "> 필요한 것 : p 함수 \n",
    "\n",
    "- def p(self, vector, s) : => 한 행의 $p_{j|i}$\n",
    "\n",
    "- def p_matrix(self) : =>  P 매트릭스 \n",
    "\n",
    "- def new_p(self) : => $p_{ij}$ => $p_{ij}$ 로 조정된 매트릭스 \n",
    "\n",
    "- def q(self) : => $q_{j|i}$ 매트릭스 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cec91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tSNE() : \n",
    "    def __init__(self, X, target_p): \n",
    "        self.X = X\n",
    "        self.n = np.shape(X)[0]\n",
    "        self.y = np.random.rand(self.n, self.n)\n",
    "        self.target_p = target_p # 목표 복잡도 \n",
    "        self.s = self.find_sigma(self.X, self.target_p)\n",
    "        \n",
    "    def softmax(self, vector) :\n",
    "        vector = np.array(vector)\n",
    "        return np.exp(vector) / np.exp(vector).sum() \n",
    "    \n",
    "    def p(self, vector, s) : # => 한 벡터만 값을 반환해야 하나?  \n",
    "        vector = [(np.square(vector -self.X[i])) for i in range(self.n)] \n",
    "        vector = vector / (-2*s**2) \n",
    "        s_vector = self.softmax(vector)\n",
    "        return np.array(s_vector) \n",
    "    \n",
    "    def p_matrix(self) : \n",
    "        p_matrix = [] \n",
    "        for i in range(self.n) : \n",
    "            vector = self.p(self.X[i], self.s[i])\n",
    "            p_matrix.append(vector)\n",
    "        return np.array(p_matrix)\n",
    "        \n",
    "    def q_matrix(self) : \n",
    "        q_matrix = [] \n",
    "        for i in range(self.n) : \n",
    "            vector = np.array([-np.sum(np.square(self.y[i] - self.y[j])) for j in range(self.n)])\n",
    "            s_vector = self.softmax(vector)\n",
    "            q_matrix.append(s_vector)\n",
    "        return np.array(q_matrix)\n",
    "    \n",
    "    def new_p_matrix(self) : \n",
    "        matrix = self.p_matrix() \n",
    "        return (matrix + matrix.T)/2\n",
    "    \n",
    "    def per(self, vector, s) : # vector에는 추후 p,q matrix의 각 행을 넣을 것 \n",
    "        vector = self.p(vector, s)\n",
    "        entropy = np.sum([vector[i]*np.log2(vector)[i] for i in range(vector.shape[1])])\n",
    "        return 2**entropy \n",
    "    \n",
    "    def find_sigma(self, matrix, target_per) : # 적정한 sigma list 반환 \n",
    "        sigmas = []\n",
    "        for i in range(matrix.shape[0]) : \n",
    "            fn = lambda s : self.per(matrix[i:i+1, :],np.array(s))\n",
    "            correct_sigma = self.binary_search(fn, target_per) \n",
    "            sigmas.append(correct_sigma)\n",
    "        return np.array(sigmas) \n",
    "        \n",
    "    def binary_search(self, fn, target, tol=1e-10, max_iter=10000, lower=1e-20, upper=1000.):\n",
    "        for i in range(max_iter):\n",
    "            guess = (lower + upper) / 2.\n",
    "            val = fn(guess)\n",
    "            if val > target:\n",
    "                upper = guess\n",
    "            else:\n",
    "                lower = guess\n",
    "            if np.abs(val - target) <= tol:\n",
    "                break\n",
    "            return val \n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0f34b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4.29044535e-04, 4.29044535e-04, 4.29044535e-04, ...,\n",
       "         4.29044535e-04, 4.29044535e-04, 4.29044535e-04],\n",
       "        [4.28946668e-04, 5.92549144e-77, 3.44631630e-09, ...,\n",
       "         1.68666278e-05, 4.29044535e-04, 5.50669123e-08],\n",
       "        [4.28946854e-04, 5.92549144e-77, 3.44631630e-09, ...,\n",
       "         1.68666278e-05, 8.08083565e-08, 2.68875922e-04],\n",
       "        ...,\n",
       "        [4.28386629e-04, 5.92549144e-77, 6.62980904e-25, ...,\n",
       "         2.11975538e-11, 4.29044535e-04, 3.42410009e-04],\n",
       "        [4.26681823e-04, 5.92549144e-77, 6.62980904e-25, ...,\n",
       "         2.11975538e-11, 9.03477776e-07, 1.33823287e-04],\n",
       "        [4.28669611e-04, 5.92549144e-77, 6.62980904e-25, ...,\n",
       "         2.11975538e-11, 4.29044535e-04, 5.51183754e-06]],\n",
       "\n",
       "       [[3.58309621e-04, 4.91653591e-77, 2.87743875e-09, ...,\n",
       "         1.40872786e-05, 3.58391375e-04, 4.59822183e-08],\n",
       "        [3.58391375e-04, 3.58391375e-04, 3.58391375e-04, ...,\n",
       "         3.58391375e-04, 3.58391375e-04, 3.58391375e-04],\n",
       "        [3.58391375e-04, 3.58391375e-04, 3.58391375e-04, ...,\n",
       "         3.58391375e-04, 6.74779909e-08, 4.80995817e-10],\n",
       "        ...,\n",
       "        [3.58183788e-04, 3.58391375e-04, 1.74850485e-09, ...,\n",
       "         1.78458183e-06, 3.58391375e-04, 6.30257286e-07],\n",
       "        [3.57137192e-04, 3.58391375e-04, 1.74850485e-09, ...,\n",
       "         1.78458183e-06, 7.54510639e-07, 9.18675541e-06],\n",
       "        [3.58316407e-04, 3.58391375e-04, 1.74850485e-09, ...,\n",
       "         1.78458183e-06, 3.58391375e-04, 1.57518050e-04]],\n",
       "\n",
       "       [[3.88124136e-04, 5.32598842e-77, 3.11688019e-09, ...,\n",
       "         1.52594772e-05, 7.30929716e-08, 2.43282587e-04],\n",
       "        [3.88212524e-04, 3.88212524e-04, 3.88212524e-04, ...,\n",
       "         3.88212524e-04, 7.30929716e-08, 5.21021481e-10],\n",
       "        [3.88212524e-04, 3.88212524e-04, 3.88212524e-04, ...,\n",
       "         3.88212524e-04, 3.88212524e-04, 3.88212524e-04],\n",
       "        ...,\n",
       "        [3.87987395e-04, 3.88212524e-04, 1.89400425e-09, ...,\n",
       "         1.93307799e-06, 7.30929716e-08, 1.01425159e-04],\n",
       "        [3.86853323e-04, 3.88212524e-04, 1.89400425e-09, ...,\n",
       "         1.93307799e-06, 3.18144069e-04, 1.73459719e-05],\n",
       "        [3.88131155e-04, 3.88212524e-04, 1.89400425e-09, ...,\n",
       "         1.93307799e-06, 7.30929716e-08, 1.80183435e-07]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3.59265843e-04, 4.95623691e-77, 5.55586783e-25, ...,\n",
       "         1.77725697e-11, 3.59817604e-04, 2.87160654e-04],\n",
       "        [3.59609196e-04, 3.59817604e-04, 1.75598412e-09, ...,\n",
       "         1.79191416e-06, 3.59817604e-04, 6.32862814e-07],\n",
       "        [3.59608947e-04, 3.59817604e-04, 1.75598412e-09, ...,\n",
       "         1.79191416e-06, 6.77606232e-08, 9.40096588e-05],\n",
       "        ...,\n",
       "        [3.59817604e-04, 3.59817604e-04, 3.59817604e-04, ...,\n",
       "         3.59817604e-04, 3.59817604e-04, 3.59817604e-04],\n",
       "        [3.59373635e-04, 3.59817604e-04, 3.59817604e-04, ...,\n",
       "         3.59817604e-04, 7.57626531e-07, 2.49693647e-04],\n",
       "        [3.59784400e-04, 3.59817604e-04, 3.59817604e-04, ...,\n",
       "         3.59817604e-04, 3.59817604e-04, 2.67748753e-05]],\n",
       "\n",
       "       [[3.63057332e-04, 5.02952880e-77, 5.63724640e-25, ...,\n",
       "         1.80322424e-11, 7.68686648e-07, 1.13866345e-04],\n",
       "        [3.63790243e-04, 3.65067758e-04, 1.78163113e-09, ...,\n",
       "         1.81807139e-06, 7.68686648e-07, 9.35876474e-06],\n",
       "        [3.63789623e-04, 3.65067758e-04, 1.78163113e-09, ...,\n",
       "         1.81807139e-06, 2.99178191e-04, 1.63130945e-05],\n",
       "        ...,\n",
       "        [3.64617311e-04, 3.65067758e-04, 3.65067758e-04, ...,\n",
       "         3.65067758e-04, 7.68686648e-07, 2.53337072e-04],\n",
       "        [3.65067758e-04, 3.65067758e-04, 3.65067758e-04, ...,\n",
       "         3.65067758e-04, 3.65067758e-04, 3.65067758e-04],\n",
       "        [3.64337619e-04, 3.65067758e-04, 3.65067758e-04, ...,\n",
       "         3.65067758e-04, 7.68686648e-07, 1.32315382e-04]],\n",
       "\n",
       "       [[3.51885089e-04, 4.85108179e-77, 5.43809428e-25, ...,\n",
       "         1.73959120e-11, 3.52192861e-04, 4.52422682e-06],\n",
       "        [3.52119190e-04, 3.52192861e-04, 1.71877046e-09, ...,\n",
       "         1.75394098e-06, 3.52192861e-04, 1.54796784e-04],\n",
       "        [3.52119044e-04, 3.52192861e-04, 1.71877046e-09, ...,\n",
       "         1.75394098e-06, 6.63246458e-08, 1.63495157e-07],\n",
       "        ...,\n",
       "        [3.52160360e-04, 3.52192861e-04, 3.52192861e-04, ...,\n",
       "         3.52192861e-04, 3.52192861e-04, 2.62074893e-05],\n",
       "        [3.51488471e-04, 3.52192861e-04, 3.52192861e-04, ...,\n",
       "         3.52192861e-04, 7.41571258e-07, 1.27648826e-04],\n",
       "        [3.52192861e-04, 3.52192861e-04, 3.52192861e-04, ...,\n",
       "         3.52192861e-04, 3.52192861e-04, 3.52192861e-04]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tSNE(X, 0.1)\n",
    "test.p_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee3724d",
   "metadata": {},
   "source": [
    "### 2. 저차원 표현에 대한 비용 함수 - Kullback Leiber divergence - 설정하여, gradient 값 구하기 \n",
    "\n",
    "### 3. $y_i$에 대한 gradient 값을 기반으로 gradient descent 방법을 통해 y값 근접시키기. \n",
    "\n",
    "**구현해야하는 것** \n",
    "- Kullback Leiber 함수 \n",
    "- $\\frac {\\delta C}{\\delta y_i}$ \n",
    "\n",
    "**필요한 것**\n",
    "- l_rate : 학습율 \n",
    "- p matrix \n",
    "- q matrix \n",
    "- y 값 \n",
    "\n",
    "**함수의 형태**\n",
    "- def kullback(self, p_matrix, q_matrix) : => 단일 값 반환  \n",
    "\n",
    "- def gradient(self) : => (n x 1) 벡터 반환\n",
    "\n",
    "- def tsne_goal(self) : => y matrix 반환 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6b823a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tSNE() : \n",
    "    def __init__(self, X, target_p, learning_rate): \n",
    "        self.X = X\n",
    "        self.n, self.d = np.shape(X)\n",
    "        self.y = np.random.rand(self.n, self.d)\n",
    "        \n",
    "        self.l = learning_rate\n",
    "        self.target_p = target_p # 목표 복잡도 \n",
    "        self.s = self.find_sigma(self.X, self.target_p)\n",
    "        \n",
    "    def softmax(self, vector) :\n",
    "        vector = np.array(vector)\n",
    "        return np.exp(vector) / np.exp(vector).sum() \n",
    "    \n",
    "    def p(self, vector, s) : # => 한 벡터만 값을 반환해야 하나?  \n",
    "        vector = [(np.square(vector -self.X[i])) for i in range(self.n)] \n",
    "        vector = vector / (-2*s**2) \n",
    "        s_vector = self.softmax(vector)\n",
    "        return np.array(s_vector) \n",
    "    \n",
    "    def p_matrix(self) : \n",
    "        p_matrix = [] \n",
    "        for i in range(self.n) : \n",
    "            vector = self.p(self.X[i], self.s[i])\n",
    "            p_matrix.append(vector)\n",
    "        return np.array(p_matrix)\n",
    "        \n",
    "    def q_matrix(self) : \n",
    "        q_matrix = [] \n",
    "        for i in range(self.n) : \n",
    "            vector = np.array([-np.sum(np.square(self.y[i] - self.y[j])) for j in range(self.n)])\n",
    "            s_vector = self.softmax(vector)\n",
    "            q_matrix.append(s_vector)\n",
    "        return np.array(q_matrix)\n",
    "    \n",
    "    def new_p_matrix(self) : \n",
    "        matrix = self.p_matrix() \n",
    "        return (matrix + matrix.T)/2\n",
    "    \n",
    "    def per(self, vector, s) : # vector에는 추후 p,q matrix의 각 행을 넣을 것 \n",
    "        vector = self.p(vector, s)\n",
    "        entropy = np.sum([vector[i]*np.log2(vector)[i] for i in range(vector.shape[1])])\n",
    "        return 2**entropy \n",
    "    \n",
    "    def find_sigma(self, matrix, target_per) : # 적정한 sigma list 반환 \n",
    "        sigmas = []\n",
    "        for i in range(matrix.shape[0]) : \n",
    "            fn = lambda s : self.per(matrix[i:i+1, :],np.array(s))\n",
    "            correct_sigma = self.binary_search(fn, target_per) \n",
    "            sigmas.append(correct_sigma)\n",
    "        return np.array(sigmas) \n",
    "        \n",
    "    def binary_search(self, fn, target, tol=1e-10, max_iter=10000, lower=1e-20, upper=1000.):\n",
    "        for i in range(max_iter):\n",
    "            guess = (lower + upper) / 2.\n",
    "            val = fn(guess)\n",
    "            if val > target:\n",
    "                upper = guess\n",
    "            else:\n",
    "                lower = guess\n",
    "            if np.abs(val - target) <= tol:\n",
    "                break\n",
    "        return val\n",
    "    \n",
    "    def kullback(self, new_p_matrix, q_matrix) : \n",
    "        return np.sum(new_p_matrix * np.log(new_p_matrix / q_matrix)) \n",
    "    \n",
    "    def gradient(self, new_p_matrix, q_matrix) : \n",
    "        gradient_lst = [] \n",
    "        for i in range(self.n ) : \n",
    "            gradient = np.sum(4*[np.dot((self.y[i]-self.y[j]), (new_p_matrix[i,j] - q_matrix[i,j])) / (1 + np.square(self.y[i] -self.y[j])) for j in range(len(new_p_matrix))]) \n",
    "            gradient_lst.append(gradient)\n",
    "        return gradient_lst\n",
    "    \n",
    "    def tsne_goal(self, num_iter) : \n",
    "        new_p_matrix = self.new_p_matrix()\n",
    "        \n",
    "        for i in range(num_iter) : \n",
    "            q_matrix = self.q_matrix() \n",
    "            gradient_vector = self.gradient(new_p_matrix, q_matrix)\n",
    "            self.y = self.y + self.l*gradient_vector.T\n",
    "        return self.y\n",
    "                              \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57e471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-641559a95f16>:42: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropy = np.sum([vector[i]*np.log2(vector)[i] for i in range(vector.shape[1])])\n",
      "<ipython-input-15-641559a95f16>:42: RuntimeWarning: invalid value encountered in multiply\n",
      "  entropy = np.sum([vector[i]*np.log2(vector)[i] for i in range(vector.shape[1])])\n"
     ]
    }
   ],
   "source": [
    "test = tSNE(X, 0.1, 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
