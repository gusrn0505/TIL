{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e18c81c",
   "metadata": {},
   "source": [
    "# Ensemble Learning - Light GBM \n",
    "\n",
    "### Algorithm 2 : Gradient-based one-side Sampling \n",
    "Input : I : Training Data, d : iterations \n",
    "\n",
    "Input : a: sampling ratio of large gradient data \n",
    "\n",
    "Input : b: sampling ratio of small gradient data \n",
    "\n",
    "Input : loss : loss function, L : weak learner \n",
    "\n",
    "\n",
    "1. models <- {}, fact <- $\\frac{1-a}{b}$\n",
    "2. topN <- a x len(I), randN <- b x len(I) \n",
    "3. for i = 1 to d do \n",
    "- preds <- model.predict(I)\n",
    "- g < - loss(I, preds), w <- {1,1,...} \n",
    "- sorted <- GetSortedIndices(abs(g)) \n",
    "- topSet <- sorted[1:topN] \n",
    "- randSet <- RandomPick*sorted[topN:len(I)], randN) \n",
    "- usedSet <- topSet + randSet \n",
    "- w[randSet] x fact > Assign weight fact to the small gradient data\n",
    "- newModel <- L(I[usedSet], -g[usedSet], w[usedSet])\n",
    "- models.append(newModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8ea64",
   "metadata": {},
   "source": [
    "**구현해야 하는 것**\n",
    "- model : 모듈에서 불러올 것. models의 데이터 타입이 무엇인지 고민 필요. \n",
    "- GetSortedIndices : np.argsort로 구현 \n",
    "- RandomPick : np.random.choice 로 구현 \n",
    "- L(Data, weight) : Weak Learner. 입력값으로 Data와 weight 둘을 받아야 함. weight 을 어떻게 해석하고 받아들여야 하는지 고민필요 \n",
    "\n",
    "**필요로 하는 것**\n",
    "- I : Training Data \n",
    "- d : iterations \n",
    "- a : sampling ratio of large gradient data \n",
    "- b : sampling ratio of small gradient data \n",
    "- loss : loss function \n",
    "- L : weak learner \n",
    "\n",
    "**함수의 형태** \n",
    "- def __init__(self, I, d, a, b, loss, L) : \n",
    "\n",
    "\n",
    "외부 함수 \n",
    "- def loss(pred_y,y) : OLS 결과값 반환 \n",
    "- def stump_tree(data, weight) : weight 를 어떻게 반영해야 할까? Ababoost에선 마지막에 $\\alpha_i$ 값을 따로 구해서 합쳤었는데. Stump Tree 함수 내부에선 어떻게 구현해줘야 할까. 함수값을 +1, -1 외로 바꾸면 안됨. 그럼 식이 성립하지 않음.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71b90fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rand\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "X = load_iris()['data'][:100]\n",
    "\n",
    "# y의 값을 +1, -1 둘 중 하나로 변경 \n",
    "y = load_iris()[\"target\"][:100]\n",
    "y[:50] = -1\n",
    "y= y.reshape(-1,1)\n",
    "S = np.concatenate((X,y), axis=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from scipy.stats import norm\n",
    "from sys import maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45eab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 함수로는 OLS를 가정하겠음. \n",
    "def loss(pred_y,y) : \n",
    "    return np.sum([0.5 * (pred_y[i] - y[i])**2  for i in range(len(y))])\n",
    "\n",
    "# Weak Learner 로는 Stump_tree 를 채택하겠음. 단, 아래 함수에서 w input을 어떻게 반영할 지 고민필요.\n",
    "# 여기서 Data는 X,y 가 합쳐진 것임. \n",
    "# Stump tree는 이진 분류로 y의 값은 +1, -1 둘 중의 하나의 값을 가져야함.\n",
    "def stump_tree(data, weight, chose_att = None, crit = None, direction = None) : \n",
    "    # np.array로 가정하지 않으면 indexing을 위해 list를 입력할 수 없음. \n",
    "    data = np.array(data)\n",
    "    weight = np.array(weight)\n",
    "    if chose_att is None : \n",
    "        chose_var = data[np.random.choice(range(len(data)))]\n",
    "        chose_att = np.random.choice(range(np.shape(data)[1]-1))\n",
    "        crit = chose_var[chose_att]\n",
    "    \n",
    "    #right, left 에는 기준점을 중심으로 좌우에 해당하는 Index 들을 저장함. \n",
    "    left = [] \n",
    "    right = [] \n",
    "    result = np.zeros(len(data))\n",
    "    for index in range(len(data)) : \n",
    "        if data[index][chose_att] > crit : right.append(index)\n",
    "        else : left.append(index)\n",
    "\n",
    "    # result에 weight의 값을 입력함. 추후 각 Stump_tree의 결과값을 합쳤을 때 바로 weight가 반영되도록\n",
    "    right_result = [1 if data[right][i,-1] == 1 else 0 for i in range(len(right)) ] \n",
    "    left_result = [1 if data[left][i,-1] == -1 else 0 for i in range(len(left)) ]\n",
    "    if direction is None : \n",
    "        if np.sum(right_result) + np.sum(left_result) > len(data)/2 : \n",
    "            result[right] = weight[right]\n",
    "            result[left] = weight[left] * (-1)\n",
    "            direction = \"right\" \n",
    "        else : \n",
    "            result[right] = weight[right] * (-1)\n",
    "            result[left] = weight[left]\n",
    "            direction = \"left\"\n",
    "            \n",
    "    else : \n",
    "        if direction == \"right\" : \n",
    "            result[right] = weight[right]\n",
    "            result[left] = -weight[left]\n",
    "        else : \n",
    "            result[right] = -weight[right]\n",
    "            result[left] = weight[left]\n",
    "            \n",
    "    return result, chose_att, crit, direction \n",
    "\n",
    "def cal_stump_tree(vector, chose_att, crit, direction) :\n",
    "    if vector[chose_att] > crit :\n",
    "        if direction == \"right\":  return 1\n",
    "        else : return -1 \n",
    "        \n",
    "    else : \n",
    "        if direction == \"right\" : return -1 \n",
    "        else : return 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe7cd155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGMB() : \n",
    "    def __init__(self, I, d, a,b,loss, weak_learner) : \n",
    "        # X, y가 결합한 형태가 I 임 \n",
    "        self.data = I\n",
    "        self.X = np.array(I)[:, :-1]\n",
    "        self.y = np.array(I)[:, -1]\n",
    "        self.n, self.m = np.shape(I)\n",
    "        \n",
    "        self.d = d \n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "        self.loss = loss \n",
    "        self.weak_learner = weak_learner\n",
    "        \n",
    "    def algorithm_2(self) : \n",
    "        # model에 대해선 []로 구현하겠음. Stump_tree 함수에 최적화 진행\n",
    "        models = [[self.weak_learner, [None, None, None]]]\n",
    "        fact = (1 - self.a)/self.b \n",
    "        topN = a * self.n \n",
    "        randN = b * self.n \n",
    "        \n",
    "        for i in range(self.d) : \n",
    "            weight = np.ones(self.n)\n",
    "            pred = [1 if np.sum(model_set[0](self.I, weight, *model_set[1])) > 0 else -1 for model_set in models]\n",
    "            g = self.loss(pred, self.y)\n",
    "            \n",
    "            sort_index = np.argsort(abs(np.array(g)))\n",
    "            topSet = sort_index[:topN]\n",
    "            randSet = rand.sample(sort_index[topN:], randN)\n",
    "            usedSet = topSet + randSet\n",
    "             \n",
    "            # gradient가 1보다 같거나 작도록 설정하기. \n",
    "            w[randSet] = np.array(g)[randSet] * fact\n",
    "            \n",
    "            criterion = stump_tree(np.array(self.data[usedSet]) - np.array(g[usedSet]), w[usedSet])\n",
    "            newModel = [stump_tree, [criterion[1:]]]\n",
    "            models.append(newModel)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb630be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "a = tree.DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "151f819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [None, None, None]\n",
    "c = np.ones(len(S))\n",
    "b = stump_tree(S, c, *a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef07b33",
   "metadata": {},
   "source": [
    "### Altorithm 3 : Greedy Bundling \n",
    "\n",
    "Input : F : features, K : max conflict count\n",
    "1. construct graph G \n",
    "2. searchOrder <- G.sortBydegree() \n",
    "3. bundles <- {}, bundlesConflict <- {} \n",
    "- for i in seachOrder do \n",
    "- needNew <- True \n",
    "\n",
    "> for j =1 to len(bundels) do \n",
    "\n",
    "> cnt <- ConflictCnt(bundels[j], F[i]) \n",
    "\n",
    "> if cnt + bundlesConflict[i] <= K then\n",
    "> - bundle[j].add(F[i]), needNew <- False \n",
    "> - break \n",
    "\n",
    "- if needNew then \n",
    "> Add F[i] as a new bundle to bundels \n",
    "\n",
    "output : bundles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc222a6",
   "metadata": {},
   "source": [
    "**구현해야 하는 것**\n",
    "- graph : 각 특성간 conflict 그래프. d x d 매트릭스 \n",
    "- bundles : 공 list []. \n",
    "- bundlesConflict : np.zeros(len(features). (d, ) list\n",
    "- ConflictCnt(bundels[j], F[i]) : j 번째 bundel과 i번째 특성 간 conflict 개수 \n",
    "\n",
    "**필요로 하는 것**\n",
    "- F : 특성값. \n",
    "- K : cut-off 지점\n",
    "\n",
    "**함수의 형태**\n",
    "- def graph(X) : X를 넣으면 각 특성간 conflict 개수를 원소값으로 가지는 graph 반환\n",
    "\n",
    "- def algorithm_3(self, F, K) : bundle을 반환 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb9cffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(data) : \n",
    "    n, d = np.shape(data) \n",
    "    matrix = np.zeros((d,d))\n",
    "    \n",
    "    for j in range(d) :  \n",
    "        # 기준 특성으로부터 그 다음 특성으로 넘기는 t값 설정 \n",
    "        for t in range(1, d-j) : \n",
    "            cnt = 0 \n",
    "            for i in range(n) : \n",
    "                if data[i][j] == 0 and data[i][j+t] ==0 : pass \n",
    "                cnt += 1 \n",
    "            matrix[j, j+t] = cnt \n",
    "            matrix[j+t, j] = cnt \n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abfb97e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 100., 100., 100.],\n",
       "       [100.,   0., 100., 100.],\n",
       "       [100., 100.,   0., 100.],\n",
       "       [100., 100., 100.,   0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f1f2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGMB() : \n",
    "    def __init__(self, I, d, a,b,loss, weak_learner) : \n",
    "        # X, y가 결합한 형태가 I 임 \n",
    "        self.data = I\n",
    "        self.X = np.array(I)[:, :-1]\n",
    "        self.y = np.array(I)[:, -1]\n",
    "        self.n, self.m = np.shape(I)\n",
    "        \n",
    "        self.d = d \n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "        self.loss = loss \n",
    "        self.weak_learner = weak_learner\n",
    "        \n",
    "    def algorithm_2(self) : \n",
    "        # model에 대해선 []로 구현하겠음. Stump_tree 함수에 최적화 진행\n",
    "        models = [[self.weak_learner, [None, None, None]]]\n",
    "        fact = (1 - self.a)/self.b \n",
    "        topN = a * self.n \n",
    "        randN = b * self.n \n",
    "        \n",
    "        for i in range(self.d) : \n",
    "            weight = np.ones(self.n)\n",
    "            pred = [1 if np.sum(model_set[0](self.I, weight, *model_set[1])) > 0 else -1 for model_set in models]\n",
    "            g = self.loss(pred, self.y)\n",
    "            \n",
    "            sort_index = np.argsort(abs(np.array(g)))\n",
    "            topSet = sort_index[:topN]\n",
    "            randSet = rand.sample(sort_index[topN:], randN)\n",
    "            usedSet = topSet + randSet\n",
    "             \n",
    "            # gradient가 1보다 같거나 작도록 설정하기. \n",
    "            w[randSet] = np.array(g)[randSet] * fact\n",
    "            \n",
    "            criterion = stump_tree(np.array(self.data[usedSet]) - np.array(g[usedSet]), w[usedSet])\n",
    "            newModel = [stump_tree, [criterion[1:]]]\n",
    "            models.append(newModel)\n",
    "        \n",
    "    # Feature은 __init__을 통해서 구현할 수 있으므로 제외    \n",
    "    # bundlesConflict 에 대해선 구현 x. 오히려 다른 방식으로 구현하는게 더 이해가 감. \n",
    "    def algorithm_3(self, K) : \n",
    "        graph_matrix = graph(self.X)\n",
    "        searchOrder = np.argsort(np.sum(graph, axis=0))\n",
    "        bundles = [] \n",
    "        \n",
    "        # 각 특성 i를 기준으로 Bundle에 분류하는 과정.\n",
    "        #bundel list에 저정하는 것은 특성 index로 변경 \n",
    "        for i in searchOrder : \n",
    "            needNew = True \n",
    "            \n",
    "            if bundles == [] : \n",
    "                bundles.append([i]) \n",
    "                pass \n",
    "            \n",
    "            # 번들별 추가로 넣을 것이 있는지 확인. \n",
    "            for j in range(1, max(2, len(bundle))) : \n",
    "                for t in searchOrder[i+1:] : \n",
    "                    if graph[i][t] <= K : \n",
    "                        bundle[j-1].append(t)\n",
    "                        needNew = False \n",
    "                        \n",
    "        \n",
    "            # 앞서서 bundle 사이에 추가를 안했다면 새로운 번들 형성 \n",
    "            if needNew == True : \n",
    "                bundles.append([i])\n",
    "                \n",
    "        return bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9efed42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 2) : \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47499bac",
   "metadata": {},
   "source": [
    "### Algorithm 4 : Merge Exclusive Features \n",
    "Input : numData : number of Data \n",
    "\n",
    "Input : F : One bundle of exclusive featrues\n",
    "* Algorithm 3에서 bundel 별 index를 제시했음. 이에 F 값 대신에 bundel 별 index를 인자로 받도록 하겠음. \n",
    "\n",
    "\n",
    "1. binRanges <- {0}, totalBin <- 0 \n",
    "2. for f in F do \n",
    "- totalBin += f.numBin\n",
    "- binRanges.append(totalBin)\n",
    "\n",
    "3. newBin <- new Bin(numData) \n",
    "4. for i =1 to numData do \n",
    "- newBin[i] <- 0\n",
    "\n",
    "> for j =1 to len(F) do \n",
    "> - if F[j].bin[i] != 0 then \n",
    "> - newBin[i] <- F[j].bin[i] + binRanges[j] \n",
    "\n",
    "Output : newBin, binRanges \n",
    "\n",
    "\n",
    "---\n",
    "구현하는 것 \n",
    "- 각 번들 별로 특성 값을 합쳐줌 \n",
    "\n",
    "> 1)기준변수만 값이 있을 경우 : 기준 변수의 값을 그대로 사용한다.\n",
    "\n",
    "> 2)비기준변수만 값이 있을 경우 : 기준 변수의 최대값을 더해준다.\n",
    "\n",
    "> 3)Conflict가 발생할 경우 & 둘다 0일 경우 : 기준 변수의 값을 채택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a1c1c",
   "metadata": {},
   "source": [
    "**구현해야 하는 것**\n",
    "- 기준변수의 최대값 \n",
    "- Conflict 유무 확인 \n",
    "\n",
    "- F : 인자로 bundle index를 받았을 때, 데이터의 해당 특성 값만 산출해야함. \n",
    "- newBin : 번들 내 특성값을 전체 합한 결과 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGMB() : \n",
    "    def __init__(self, I, d, a,b,loss, weak_learner) : \n",
    "        # X, y가 결합한 형태가 I 임 \n",
    "        self.data = I\n",
    "        self.X = np.array(I)[:, :-1]\n",
    "        self.y = np.array(I)[:, -1]\n",
    "        self.n, self.m = np.shape(I)\n",
    "        \n",
    "        self.d = d \n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "        self.loss = loss \n",
    "        self.weak_learner = weak_learner\n",
    "    \n",
    "    def algorithm_2(self) : \n",
    "        # model에 대해선 []로 구현하겠음. Stump_tree 함수에 최적화 진행\n",
    "        models = [[self.weak_learner, [None, None, None]]]\n",
    "        fact = (1 - self.a)/self.b \n",
    "        topN = a * self.n \n",
    "        randN = b * self.n \n",
    "        \n",
    "        for i in range(self.d) : \n",
    "            weight = np.ones(self.n)\n",
    "            pred = [1 if np.sum(model_set[0](self.I, weight, *model_set[1])) > 0 else -1 for model_set in models]\n",
    "            g = self.loss(pred, self.y)\n",
    "            \n",
    "            sort_index = np.argsort(abs(np.array(g)))\n",
    "            topSet = sort_index[:topN]\n",
    "            randSet = rand.sample(sort_index[topN:], randN)\n",
    "            usedSet = topSet + randSet\n",
    "             \n",
    "            # gradient가 1보다 같거나 작도록 설정하기. \n",
    "            w[randSet] = np.array(g)[randSet] * fact\n",
    "            \n",
    "            criterion = stump_tree(np.array(self.data[usedSet]) - np.array(g[usedSet]), w[usedSet])\n",
    "            newModel = [stump_tree, [criterion[1:]]]\n",
    "            models.append(newModel)\n",
    "        \n",
    "    # Feature은 __init__을 통해서 구현할 수 있으므로 제외    \n",
    "    # bundlesConflict 에 대해선 구현 x. 오히려 다른 방식으로 구현하는게 더 이해가 감. \n",
    "    def algorithm_3(self, K) : \n",
    "        graph_matrix = graph(self.X)\n",
    "        searchOrder = np.argsort(np.sum(graph, axis=0))\n",
    "        bundles = [] \n",
    "        \n",
    "        # 각 특성 i를 기준으로 Bundle에 분류하는 과정.\n",
    "        #bundel list에 저정하는 것은 특성 index로 변경 \n",
    "        for i in searchOrder : \n",
    "            needNew = True \n",
    "            \n",
    "            if bundles == [] : \n",
    "                bundles.append([i]) \n",
    "                pass \n",
    "            \n",
    "            # 번들별 추가로 넣을 것이 있는지 확인. \n",
    "            for j in range(1, max(2, len(bundle))) : \n",
    "                for t in searchOrder[i+1:] : \n",
    "                    if graph[i][t] <= K : \n",
    "                        bundle[j-1].append(t)\n",
    "                        needNew = False \n",
    "                        \n",
    "        \n",
    "            # 앞서서 bundle 사이에 추가를 안했다면 새로운 번들 형성 \n",
    "            if needNew == True : \n",
    "                bundles.append([i])\n",
    "                \n",
    "        return bundles\n",
    "    \n",
    "    def algorithm_4(self, index_list) : \n",
    "        F = self.X[:, index_list].T \n",
    "        \n",
    "        max_first_feature = np.max(F[0])\n",
    "        newBin = F[0]\n",
    "        \n",
    "        for j in range(1,len(index_list)) : \n",
    "            \n",
    "            for i in range(self.n) : \n",
    "                if newBin[i] == 0 and F[j][i] != 0 : \n",
    "                    newBin[i] = F[j][i] + max_first_feature \n",
    "        \n",
    "        return newBin \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a3435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36672efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ac61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d4b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
