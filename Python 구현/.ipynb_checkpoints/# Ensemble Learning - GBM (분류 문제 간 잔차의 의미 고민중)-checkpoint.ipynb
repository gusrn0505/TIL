{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85905fbe",
   "metadata": {},
   "source": [
    "# 문제점 : 분류 문제에서 잔차를 구한다는 것은 어떠한 의미인가? \n",
    "\n",
    "예시로 이진 분류에서 y값이 -1 / +1 둘 중 하나를 띈다고 가정할 때, \n",
    "y 값의 list가 [1,1,-1-1] 이나, $f_1(x)$ 가 [1, -1, 1, -1] 로 예측했다고 하자. \n",
    "그럼 잔차 (y - f(x)) = [0 , 2, -2, 0] 이 된다. \n",
    "\n",
    "이때 -2, 0, 2 는 모두 기존 분류에서 없던 값들이다. 그렇다면 잔차를 다시 추정하는 $f_2(x)$ 는 $f_1(x)$와 달리 3분류를 진행하는 것인가? \n",
    "\n",
    "$f_n(x)$ 함수는 계속해서 Class의 개수가 늘어날 텐데 이렇게 계산하는 것이 맞나?\n",
    "\n",
    "알고리즘 구현 간 크게 실수 한 부분 중 하나는 회귀모델을 사용해야 하는데, 결정 모델로 잔차를 구하고자 한 점. \n",
    "\n",
    "##### 잔차를 구할 때, 예측값인 f(x)를 클래스 분류 결과가 아닌, 해당 클래스일 확률로 구한다. \n",
    "클래스별로 One-hot incoding 을 진행하며, 클래스별 개수 만큼의 Dataset를 분리한다. \n",
    "각 클래스 별로 Decision Tree Regression을 통해서 예측값을 구한다. \n",
    "\n",
    "확률 값은 Softmax를 통해 구한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c79473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3576b15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "681f2d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43605144",
   "metadata": {},
   "source": [
    "# Ensemble Learning - GBM \n",
    "\n",
    "### 수도 알고리즘은 강의 자료 참고 \n",
    "\n",
    "1. Initialize $f_0(x)$ = $argmin_\\gamma \\sum_{i=1}^N L(y_i, \\gamma)$ \n",
    "2. For m = 1 to M \n",
    "- for i = 1, ... N compute \n",
    "> $g_{im} = [\\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)}]_{f(x_i) = f_{m-1}(x_i)}$ \n",
    "- Fit a regression tree to the targets $g_{im}$ giving terminal regions $R_{jm}, j=1, ... , J_m$ \n",
    "- For j=1, ..., $J_m$ compute \n",
    "> $\\gamma_jm$ = $argmin_\\gamma \\sum_{x_i \\in R_{jm}} L(y_i, f_{m-1}(x_i) + \\gamma)$\n",
    "- update $f_m(x) = f_{m-1}(x) + \\sum_{j=1}^{J_m} \\gamma_{jm} I(x \\in R_{jm})$ \n",
    "3. Output $\\hat f(x) = f_M(x)$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd530146",
   "metadata": {},
   "source": [
    "**구현해야 하는 것**\n",
    "- $f_0(x)$ = $argmin_\\gamma \\sum_{i=1}^N L(y_i, \\gamma)$  : 임의의 Stump tree 진행. \n",
    "- $\\gamma_jm$ = $argmin_\\gamma \\sum_{x_i \\in R_{jm}} L(y_i, f_{m-1}(x_i) + \\gamma)$ : y- $f_1(x)$ 로 Dataset의 값을 변경시키고, 이를 예측하는 Stump tree 적용\n",
    "* 원래는 함수를 더해가는 게 맞으나, 함수를 더하는 과정을 어떻게 구현할지 감이 안옴. 이에 데이터를 변경시키는 쪽으로 구현하겠음. \n",
    "\n",
    "- f(x) : 약한 학습기. Stump tree 적용 \n",
    "- loss 함수 : OLS 적용\n",
    "- Aggregation 함수 : Majority 함수 채택 \n",
    "\n",
    "**필요한 것** \n",
    "- Data : Stump Tree를 적용할 것으로 y값이 1, -1로 구분될 것 \n",
    "- M : 트리 개수\n",
    "- Aggregating 방식 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28b1a0",
   "metadata": {},
   "source": [
    "### GBM 알고리즘 변경안\n",
    "\n",
    "1. 클래스 레이블을 기준으로 one-hot encoding을 진행한다. \n",
    "2. 각 클래스 별 one-hot encoding 렬을 y 값으로 하여 Decision tree regression을 진행한다. \n",
    "3. Regression 의 결과에 softmax를 적용하여 각 레이블 별 확률 값을 구한다. (따로 Column 을 만들어야 함.) \n",
    "\n",
    "3. 잔차를 계산한 후, -잔차를 y값에 부여한다.\n",
    "4. 갱신된 y값에 따라 새롭게 Decision tree regression을 진행하여 y 값을 예측한다. \n",
    "\n",
    "위의 과정을 M번 반복하면서 정확도를 향상시킨다. \n",
    "\n",
    "**구현해야 하는 것**\n",
    "- One - hot encoding \n",
    "- Decision tree regression : 모듈 사용 \n",
    "- Softmax\n",
    "\n",
    "**필요한 것**\n",
    "- M : 반복 학습 횟수 \n",
    "- X : Input data\n",
    "- y : output data \n",
    "\n",
    "**함수의 형태** \n",
    "- Softmax는 개별 구현 \n",
    "- 그 외 One-hot encoding 등 다른 기능은 Class 내에서 구현할 것. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7110c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "X = load_iris()['data']\n",
    "\n",
    "# y의 값을 +1, -1 둘 중 하나로 변경 \n",
    "y = load_iris()[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4f318c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x) : \n",
    "    e = np.exp(np.array(x))\n",
    "    return e/np.sum(e) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e23639d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBM() : \n",
    "    def __init__(self, X, y, M) : \n",
    "        self.X = X \n",
    "        self.n = np.shape(X)[0]\n",
    "        self.d = np.shape(X)[1]\n",
    "        \n",
    "        self.y = y \n",
    "        self.num_label = len(np.unique(y))\n",
    "        self.one_hot_y = self.one_hot(y)\n",
    "        \n",
    "        self.M = M \n",
    "        \n",
    "        self.model_lst = self.modeling()\n",
    "    \n",
    "    \n",
    "    def one_hot(self, y) : \n",
    "        dataset = [] \n",
    "        \n",
    "        for label in range(self.num_label) : \n",
    "            data = [1 if y[i] == label else 0 for i in range(len(y))]\n",
    "            dataset.append(data)\n",
    "        return dataset\n",
    "    \n",
    "    def modeling(self) : \n",
    "        model_lst = []\n",
    "        for num in range(self.M) : \n",
    "            model_set = [] \n",
    "            pred_y_lst = [] \n",
    "\n",
    "            # 각 label 별로 DT Regression 진행 \n",
    "            for label in range(self.num_label) : \n",
    "                model = tree.DecisionTreeRegressor()\n",
    "                model.fit(self.X, self.one_hot_y[label]) \n",
    "                pred_y = model.predict(X)\n",
    "                pred_y_lst.append(pred_y)\n",
    "                model_set.append(model)\n",
    "            \n",
    "            # 각 레이블 별 예측 결과를 모아서 Softmax 진행 \n",
    "            pred_y_lst = np.array(pred_y_lst).swapaxes(0,1)\n",
    "            for i in range(np.shape(pred_y_lst)[0]) : \n",
    "                pred_y_lst[i] = softmax(pred_y_lst[i])\n",
    "            \n",
    "            pred_y_lst = pred_y_lst.swapaxes(0,1)\n",
    "            \n",
    "            grad = pred_y_lst - np.array(self.one_hot_y) \n",
    "            self.one_hot_y = grad \n",
    "            \n",
    "            model_lst.append(model_set)\n",
    "        return model_lst\n",
    "    \n",
    "    def test(self) : \n",
    "        solution_set = [] \n",
    "        for i in range(self.num_label) :\n",
    "            lst = [] \n",
    "            for num in range(self.M) : \n",
    "                lst.append(self.model_lst[num][i].predict(self.X))\n",
    "            \n",
    "            solution_set.append(lst)\n",
    "        return solution_set\n",
    "        \n",
    "    def classify(self, new_x) : \n",
    "        predict = [self.model_lst[i].predict(new_x) for i in range(self.num_label)]\n",
    "        solution = np.argmax(predict) \n",
    "        return solution\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0c03ceee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.11841078, 3.11841078, 3.11841078, 3.11841078, 3.11841078,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844,\n",
       "       3.76317844, 3.76317844, 3.76317844, 3.76317844, 3.76317844])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = GBM(X,y, 20)\n",
    "b = a.test()\n",
    "\n",
    "np.sum(b[2], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "393d6c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8587ac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 5, 8],\n",
       "       [3, 6, 9]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [] \n",
    "a = [1,2,3]\n",
    "b= [4,5,6]\n",
    "c=[7,8,9]\n",
    "\n",
    "lst.append(a)\n",
    "lst.append(b)\n",
    "lst.append(c)\n",
    "\n",
    "np.array(lst).swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf8b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8412139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc9d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178728bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e88788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af45dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66d9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69179b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e015c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80889f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1614a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00066153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8573a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2bad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
