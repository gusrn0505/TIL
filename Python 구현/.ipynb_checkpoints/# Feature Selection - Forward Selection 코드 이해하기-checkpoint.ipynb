{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1b0a4e",
   "metadata": {},
   "source": [
    "# Feature Selection - Forward Selection 코드 이해하기\n",
    "\n",
    "\n",
    "## https://heejeongchoi.github.io/hydejack/2018-10-23-Supervised-Dimension-Reduction/ \n",
    "\n",
    "따라 코드 구현을 쭉 해볼 것. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc158c",
   "metadata": {},
   "source": [
    "### 구현 간 필요한 것 \n",
    "\n",
    "1. 설명력 지표 \n",
    "- AIC / BIC / Adjusted $R^2$ 가 있음 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6aebd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0f3c744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "var_names = boston.feature_names\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "var_num = np.shape(X)[1]\n",
    "all_vars = list(np.arange(var_num))\n",
    "\n",
    "VS = Variable_Selection(model, X, y, 'AIC', var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f2ae915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable_Selection():\n",
    "    def __init__(self, model, X, y, eval_metric, feature_names):\n",
    "        '''\n",
    "        model : 적용할 모델\n",
    "        X : 입력 데이터\n",
    "        y : 타겟 데이터. 결과값\n",
    "        eval_metric : 평가 지표. AIC 또는 adj_R_sq 가 주로 사용됨\n",
    "        feature_names : 입력 데이터의 속성명\n",
    "        '''\n",
    "\n",
    "        self.model = model\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.eval_metric = eval_metric\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "        self.n = np.shape(X)[0]\n",
    "        # np.shape는 X의 형태를 의미. np.shape(X)[0]는 개수를, np.shape(X)[1]는 속성의 개수를 의미함\n",
    "        self.var_num = np.shape(X)[1]\n",
    "        self.all_vars = list(np.arange(self.var_num))\n",
    "        # np.arange(self.var_num) 은 array([0,1,2,3,4, ... self.var_num-1]) 를 의미한다. 즉, 여기선 index를 표현한 것으로 볼 수 있다.\n",
    "\n",
    "    def metric(self, used_vars):\n",
    "        used_X = np.take(self.X, used_vars, axis=1)\n",
    "        # X 입력 데이터의 axis=1, 즉 속성값에 대해서 used_vars의 인덱스에 따라서 array 형태로 값을 추출해라\n",
    "        # Q.각 속성 값을 array 형태로 빼내는 건데, 꼭 np.take로 빼야하는건가? indexing 으로는 안되나?\n",
    "        # > 나중에 사용하고 싶은 변수만 설정하여 뽑아낼 수 있음. 그래서 used_vars로 명명한 것으로 보임 \n",
    "        \n",
    "        fitted_model = self.model.fit(used_X, self.y)\n",
    "        # 입력값과 그에 따른 결과값을 입력함. 결과는 어떤 형태로 출력되는 거지? \n",
    "        #> Linear Regression() 으로 결과가 나옴. 즉, 함수의 형태로 나오는 것이고 답이 나오는 것은 아님. \n",
    "        \n",
    "        # fit() 메서드는 선형 회귀 모델에 필요한 두가지 변수를 전달하는 것 \n",
    "        # 기울기 : line_fitter.coef / 절편 ㅣ line_fitter.intercept \n",
    "        # Q. 위의 fitted_model은 used_X를 기울기로, self.y를 절편으로 받아들인다는 건가? \n",
    "        \n",
    "        \n",
    "        y_pred = fitted_model.predict(used_X)\n",
    "        \n",
    "        SSE = np.sum((self.y - y_pred)**2) #(실제값 - 예측값)^2 \n",
    "        SST = np.sum((self.y - np.mean(self.y))**2 )\n",
    "        AIC = self.n * np.log(SSE / self.n) + 2*len(used_vars) \n",
    "        adj_R_sq = 1 - (self.n -1) / self.n - (len(used_vars) +1 )* SSE/SST\n",
    "        \n",
    "        return {\"AIC\" : AIC, \"adj_R_sq\": adj_R_sq}, fitted_model\n",
    "\n",
    "    \n",
    "    def p_value(self, fitted_model, used_vars): # 목적 : 각 속성별로 얼마나 영향을 미치나 체크. \n",
    "        used_X = np.take(self.X, used_vars, axis=1)\n",
    "        params = np.append(fitted_model.intercept_, fitted_model.coef_)\n",
    "        y_pred = fitted_model.predict(used_X)\n",
    "\n",
    "        const_X = pd.DataFrame({\"Constant\": np.ones(len(used_X))}).join(pd.DataFrame(used_X))\n",
    "        # \"Constant\" 를 제목으로 하는 한 열에는 모두 값을 1을, 나머지는 속성 열에 맞춰 각 값을 가지게 함.\n",
    "        \n",
    "        MSE = (sum((self.y - y_pred) ** 2)) / (len(const_X) - len(const_X.columns))\n",
    "        #  왜 분모에 전체 데이터의 개수 - 속성 열의 개수를 뺐을까? \n",
    "        # A. 그게 오차의 자유도를 의미하며, 보다 정확한 결과를 가져오기 때문. \n",
    "\n",
    "        var_b = MSE * (np.linalg.inv(np.dot(const_X.T, const_X)).diagonal())\n",
    "        # np.linalg.inv :는 역행렬을 구하는 메서드임 \n",
    "        # 분산을 구하기 위해서 const_X의 내적을 구하고 diagonal() 한 것은 이해가 되나 왜 역행렬을 보낸거지? \n",
    "        # 그리고 왜 MSE를 곱했지? \n",
    "        \n",
    "        sd_b = np.sqrt(var_b)\n",
    "        ts_b = params / sd_b\n",
    "\n",
    "        pvalue = [2 * (1 - stats.t.cdf(np.abs(i), (len(const_X) - 1))) for i in ts_b]\n",
    "        # 각 속성의 기울기들이 얼마나 영향을 주는지 확인. \n",
    "        # 이떄 pvalue는 [절편, 속성 개수] 만큼의 값들을 지니고 있음. \n",
    "\n",
    "        return pvalue[1:]\n",
    "        # 절편을 제외한 나머지 속성들의 p-value를 확인함. \n",
    "   \n",
    "    def forward_cell(self, selected_vars):\n",
    "        candidate_vars = list(set(self.all_vars) - set(selected_vars))\n",
    "\n",
    "        candidate_vars_crt, pvalues = [], []\n",
    "        # canditate_vars_Crt 가 의미하는 것은 무엇일까? \n",
    "        \n",
    "        for i in range(len(candidate_vars)):\n",
    "            used_vars = selected_vars + [candidate_vars[i]] # 순서대로 하나씩 추가 \n",
    "\n",
    "            candidate_var_crt, fitted_model = self.metric(used_vars)\n",
    "            #{\"AIC\" : AIC, \"adj_R_sq\": adj_R_sq}, fitted_model\n",
    "            # 즉, candidate_var_crt 는 {\"AIC\" : AIC, \"adj_R_sq\": adj_R_sq} 를 의미함.\n",
    "            # candidate_var\"s\"_crt 에 넣을 값들을 하나 하나 반환하기 \n",
    "            \n",
    "            candidate_vars_crt.append(candidate_var_crt[self.eval_metric])\n",
    "            # 아하 이래서 dictionary 형태로 넣었구나. \n",
    "            # AIC, adj_R_sq 둘 모두의 계산 값을 넣은 다음에 적용한 것\n",
    "            # 원하는 설명력 지표에 대한 값을 가지는 것. \n",
    "\n",
    "            pvalue = self.p_value(fitted_model, used_vars)\n",
    "            # list의 형태로 값을 받을 것이고 \n",
    "            \n",
    "            pvalues.append(pvalue)\n",
    "            #pvalues [] 에 기존 pvalue 값들 추가. \n",
    "\n",
    "        if self.eval_metric == 'AIC':\n",
    "            selected_idx = np.argmin(candidate_vars_crt)\n",
    "            # AIC는 작을수록 좋은 것 \n",
    "            \n",
    "        elif self.eval_metric == 'adj_R_sq':\n",
    "            selected_idx = np.argmax(candidate_vars_crt)\n",
    "            # adj_R_sq 는 높을 수록 좋은 것 \n",
    "\n",
    "        selected_var = candidate_vars[selected_idx]\n",
    "        selected_pvalue = pvalues[selected_idx][-1]\n",
    "\n",
    "        return selected_var, selected_pvalue\n",
    "    \n",
    "\n",
    "    def forward_selection(self, alpha):\n",
    "        selected_vars = []\n",
    "        # 모든 변수에 대해서 forward_cell을 거치면서 1개씩 변수를 추가 \n",
    "        for _ in range(self.var_num):\n",
    "            selected_var, selected_pvalue = self.forward_cell(selected_vars)\n",
    "            \n",
    "            #유의수준이 원하는 수준까지 도달하지 못하면 계속 변수를 추가. \n",
    "            if selected_pvalue <= alpha:\n",
    "                selected_vars.append(selected_var)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return self.feature_names[selected_vars]\n",
    "    # 마지막에 선택한 변수들의 이름 호출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b044476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_X = np.take(X, all_vars, axis=1)\n",
    "\n",
    "fitted_model = model.fit(used_X, y)\n",
    "\n",
    "y_pred = fitted_model.predict(used_X)\n",
    "\n",
    "        \n",
    "SSE = np.sum((y - y_pred)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "100d9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Variable_Selection(model, X, y, 'AIC', var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "529c322f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(used_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c286846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.183009411600324e-12, 0.0010849073826375566, 0.0007765982484859713, 0.7382844051646806, 0.0019222448521833968, 4.218907149189377e-06, 0.0, 0.9582287618194383, 5.804245972740318e-13, 5.039564416220443e-06, 0.0011097045319747867, 1.2658762926776035e-12, 0.0005716404814104514, 0.0]\n"
     ]
    }
   ],
   "source": [
    "const_X = pd.DataFrame({\"Constant\": np.ones(len(used_X))}).join(pd.DataFrame(used_X))\n",
    "\n",
    "\n",
    "MSE = (sum((y- y_pred) ** 2)) / (len(const_X) - len(const_X.columns))\n",
    "var_b = MSE * (np.linalg.inv(np.dot(const_X.T, const_X)).diagonal())\n",
    "\n",
    "\n",
    "params = np.append(fitted_model.intercept_, fitted_model.coef_)\n",
    "sd_b = np.sqrt(var_b)\n",
    "ts_b = params / sd_b\n",
    "\n",
    "\n",
    "pvalue = [2 * (1 - stats.t.cdf(np.abs(i), (len(const_X) - 1))) for i in ts_b]\n",
    "print(pvalue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55c8fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "print(all_vars)\n",
    "selected_vars = [0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd1906a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AIC': 2096.1876354262286, 'adj_R_sq': -2.946536439686617}\n",
      "{'AIC': 2060.275112289814, 'adj_R_sq': -2.7445241061680115}\n",
      "{'AIC': 2089.649621868097, 'adj_R_sq': -2.908683852080899}\n",
      "{'AIC': 1843.4756663396336, 'adj_R_sq': -1.7874053649949573}\n",
      "{'AIC': 2104.6293568176084, 'adj_R_sq': -2.9961398186066086}\n",
      "{'AIC': 2142.732340691568, 'adj_R_sq': -3.2306227407559085}\n",
      "{'AIC': 2132.477459347147, 'adj_R_sq': -3.1657684723671045}\n",
      "{'AIC': 2096.129295398424, 'adj_R_sq': -2.9461965060932247}\n",
      "{'AIC': 2045.4738666481512, 'adj_R_sq': -2.665348568526416}\n",
      "{'AIC': 2129.700930932229, 'adj_R_sq': -3.1484339931502916}\n",
      "{'AIC': 1828.7800086233703, 'adj_R_sq': -1.7361841130267375}\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "candidate_vars = list(set(all_vars) - set(selected_vars))\n",
    "\n",
    "candidate_vars_crt, pvalues = [], []\n",
    "        # canditate_vars_Crt 가 의미하는 것은 무엇일까? \n",
    "        \n",
    "for i in range(len(candidate_vars)):\n",
    "    used_vars = selected_vars + [candidate_vars[i]] # 순서대로 하나씩 추가 \n",
    "\n",
    "    candidate_var_crt, fitted_model = test.metric(used_vars)\n",
    "    print(candidate_var_crt)\n",
    "            #{\"AIC\" : AIC, \"adj_R_sq\": adj_R_sq}, fitted_model\n",
    "            # 즉, candidate_var_crt 는 {\"AIC\" : AIC, \"adj_R_sq\": adj_R_sq} 를 의미함.\n",
    "            # 잎사사 candidate_var_crt 는 list로 정의했었는데 이렇게 대입시켜줘도 되나? \n",
    "            \n",
    "    candidate_vars_crt.append(candidate_var_crt[\"AIC\"])\n",
    "            # 아하 이래서 dictionary 형태로 넣었구나. \n",
    "            # AIC, adj_R_sq 둘 모두의 계산 값을 넣은 다음에 적용한 것\n",
    "            # [{\"AIC\" : AIC, \"adj_R_sq\": adj_R_sq}, AIC] 이런 형태일 듯.. 맞나? \n",
    "            \n",
    "print(len(candidate_vars_crt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf54e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba76e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149565d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf4d939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c4c77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823e7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5928d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96c5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d12ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d5e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11109ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22088e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
