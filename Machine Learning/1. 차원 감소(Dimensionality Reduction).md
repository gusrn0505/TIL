# 차원 감소(Dimensionality Reduction)

출처 : 강필성 교수님의 Business Analytics 강의 

## 머신러닝 과정

1. 전처리(Pre-Processing)
   
   - 정규화 
   
   - **차원 축소**
   
   - 이미지 처리 

2. 학습 
   
   - Supervised
   
   - Unsupervised
   
   - Minimization 

3. 오류 분석(Error Analysis)
   
   - 정확도 / Recall
   
   - 과대 적합
   
   - 평가 / 교차검증 등 

### 차원 축소가 필요한 이유

1. 정보를 유지하는 차원(Intrinsic dimension)은 기존 차원에 비해 작은 경우가 있다. 차원이 높을 수록 차원의 저주에 의해 필요로 하는 사례가 많아지며, 이는 계산량 증가로 연결된다.
   
   - 고려 요소가 많을수록 모델 성능을 향상할 것 같지만, 이는 각 요소들이 독립성을 갖췄을 때에 해당한다. 이는 매우 비현실적인 전제로 변수간 의존성을 제거함으로써 차원을 축소할 수 있다. 
   
   > **차원의 저주** : 차원이 증가할 때 동일한 설명을 갖추기 위해서 필요로 하는 사례의 수가 **지수적으로 증가**한다.

2. 고차원일수록 노이즈가 생길 가능성이 높아, 예측 성능을 낮춘다 

### 차원 축소의 효과

1. 변수간 상관관계를 제거한다

2. 전처리를 단순화시킨다

3. 관련된 정보를 유지하면서 불필요한 변수를 제거한다

4. 시각화가 가능하다 

### 차원 축소의 방식

![](C:\Users\PC\Desktop\스크린샷\2.png)

- Feature Selection : 기존에 있는 변수 중 "선택" 
  
  > ex) 10개의 변수 중 설명력이 높은 3개 선택
  > 
  > Filter(Unsupervised) : 변수 선택과 모델 학습이 독립적 
  > 
  > Wrapper(Supervised) : 모델 학습의 결과에 최적화된 변수 선정  

- Feature Extraction : 기존에 있는 변수를 조합하여 최대한 많은 정보(변수, 거리 등)를 보존하는 새로운 변수를 추출. 
  
  > ex) z1 = x1 + 2x2, z2 = x3 + 3x4

---

## Feature Selection - Wrapper(Supervised)

<img src="file:///C:/Users/PC/Desktop/스크린샷/1.jpg" title="" alt="" width="453">

- 전역검사 : 모든 가능한 조합을 확인하는 것. 경우의 수 $2^n$ -1 (n : 변수의 개수)

- FS(Forward Selection) : 설명력이 높은 변수부터 차례대로 선택하는 방식 
  
  > 설명력 : 모델이 얼마나 데이터를 잘 설명하는 지를 의미. 설명력 지표(Performance Metrics)로 AIC / BIC / Adjustd $R^2$ 이 있음.

- BS(Backward Selection) : FS와 반대방향으로, 설명력이 낮은 변수부터 제거하는 방식 

- SS(Stepwise Selection) : 설명력이 높은 변수부터 선택하되, 선택된 변수들의 조합도 같이 고려

- GA(Genetic Algorithm) : 휴리스틱한 접근 방식으로, 유전학습 과정을 모방한 방식 
  
  > 휴리스틱 : 대충 어림짐작하기. 복잡한 문제를 효율적으로 시행착오를 거치며 성능을 확보

#### Genetic Algorithm 과정

1) 염색체(Chromesome) 초기화 및 파라미터 설정 
   
   - 염색체 초기화 : 각 염색체의 변수마다 랜덤하게 사용 유무 결정 
   
   - 파라미터 : 염색체 수 / 성능 평가 방식(Fitness fuction) / 교배방식(Crossover mechanism) / 돌연변이율(Rate of mutation) / 종료 조건

2) 각 염색체 선택 변수별 모델 학습 

3) 각 염색체 적합도 평가 

4) 우수 염색체 선택(Selection) 
   
   - 결정론적(Deterministic) 선택 : 성능이 좋은 상위 n%의 염색체만 선정
   
   - 확률존적(Probabilistic) 선택  : 성능에 비례하여 각 염색체가 선정될 확률 부여. 

5) 다음 세대 염색체 생성(Crossoveer & Mutation)
   
   - Crossover : 선택한 염색체들 간 변수값을 교체함. 
   
   - Mutation : 일정 확률로 변수의 값을 변경함
   
   > 이전 세대의 최고 성능을 가진 염색체는 그대로 물려주며 원하는 성능이 나오기 까지 2~5번 과정 반복
   > 
   > <img src="file:///C:/Users/PC/Desktop/스크린샷/3.jpg" title="" alt="" width="375">
6. 최종 변수 집합 선택 

--- 


