# 차원 감소(Dimensionality Reduction)

출처 : 강필성 교수님의 Business Analytics 강의 



## 머신러닝 과정

1. 전처리(Pre-Processing)
   
   - 정규화 
   
   - **차원 축소**
   
   - 이미지 처리 



2. 학습 
   
   - Supervised
   
   - Unsupervised
   
   - Minimization 



3. 오류 분석(Error Analysis)
   
   - 정확도 / Recall
   
   - 과대 적합
   
   - 평가 / 교차검증 등 



### 차원 축소가 필요한 이유

1. 정보를 유지하는 차원(Intrinsic dimension)은 기존 차원에 비해 작은 경우가 있다. 차원이 높을 수록 차원의 저주에 의해 필요로 하는 사례가 많아지며, 이는 계산량 증가로 연결된다.
   
   - 고려 요소가 많을수록 모델 성능을 향상할 것 같지만, 이는 각 요소들이 독립성을 갖췄을 때에 해당한다. 이는 매우 비현실적인 전제로 변수간 의존성을 제거함으로써 차원을 축소할 수 있다. 
   
   > **차원의 저주** : 차원이 증가할 때 동일한 설명을 갖추기 위해서 필요로 하는 사례의 수가 **지수적으로 증가**한다.

2. 고차원일수록 노이즈가 생길 가능성이 높아, 예측 성능을 낮춘다 



### 차원 축소의 효과

1. 변수간 상관관계를 제거한다

2. 전처리를 단순화시킨다

3. 관련된 정보를 유지하면서 불필요한 변수를 제거한다

4. 시각화가 가능하다 



### 차원 축소의 방식

![](C:\Users\PC\Desktop\스크린샷\3.png)

- Feature Selection : 기존에 있는 변수 중 "선택" 
  
  > ex) 10개의 변수 중 설명력이 높은 3개 선택
  > 
  > Filter(Unsupervised) : 변수 선택과 모델 학습이 독립적 
  > 
  > Wrapper(Supervised) : 모델 학습의 결과에 최적화된 변수 선정  



- Feature Extraction : 기존에 있는 변수를 조합하여 최대한 많은 정보(변수, 거리 등)를 보존하는 새로운 변수를 추출. 
  
  > ex) z1 = x1 + 2x2, z2 = x3 + 3x4



---




