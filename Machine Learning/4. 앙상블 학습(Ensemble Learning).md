# Topic 4 앙상블 학습(Ensemble Learning)

출처 : 강필성 교수님의 Business Analytics 강의

출처 : 단단한 머신러닝 챕터 8 - 앙상블 학습 



#### Ensemble Learning 기본 개념

- ###### 전제 / 상황
  
  - **모든 환경에 최고의 성능을 내는 상위의 알고리즘이란 없다(No Free Lunch Thm).** 
    
    즉, Data set의 특징에 따라 최고 성능을 내는 알고리즘이 달라진다. 
  
  - 따라서, 수많은 기술들을 적용해보는 것이 임의의 새로운 분류 문제를 푸는데 최고의 보험이다.
    
    <img title="" src="./picture/4-1.png" alt="" width="271"><img title="" src="./picture/4-2.png" alt="" width="295">
    
    > y축이 Error rate을 의미. 낮을 수록 좋다. 오른쪽은 앙상블 기법 적용 
  
  - 하지만, <mark>여러 기술들을 적절히 결합한다면, 개별 기술보다 성능이 **"대체로"** 높게 나온다.</mark>
    
    <img src="./picture/4-4.jpg" title="" alt="" width="561">



##### <mark>앙상블의 장점</mark>

![](./picture/4-28.jpg)

1. **(통계 시점)일반화 성능 저하 방지**
   
   - ****특정 단일 학습기만 사용할 때, 데이터 셋의 특징이 해당 단일 학습기와 적합히자 않다면 일반화 성능이 나빠질 수 있다.
   
   - 하지만, 여러 학습기를 합친다면 일정 이상의 일반화 성능을 보장할 수 있다.

2. **(계산 시점) 학습 알고리즘이 로컬 미니멈에 빠지는 위험한 경우를 줄여준다**
   
   - 특정 학습 방향은 로컬 미니멈에 빠질 수 있다.
   
   - 하지만 여러 방향에 대해 시도한다면(=다양한 경우를 확인한다면) 로컬 미니멈에 빠지는 경우를 줄일 수 있다.

3. **(표현의 관점) 실제 가설을 학습기로 표현할 수 없다 하더라도, 앙상블을 통해 최대한 유사한 가설을 도출할 수 있다.**
   
   - 여러 학습기의 조합, 사례의 조합을 통해 유사한 가설쪽으로 다가갈 수 있다.



- <u>Do we Need Hundreds of Classifiers to Solve Real World Classification Problem?</u>
  
  - 2014년 논문 발표 당시 모든 분류 Dataset에 대해 boosting을 제외한 모든 알고리즘을 적용함.
  
  ![](./picture/4-3.png)(상위 5위에 속하는 알고리즘)
  
  - 결론 1 : Rank가 1인 경우는 없다. (No Free Lunch)
    
    > Rank는 각 데이터셋별 알고리즘 성능 순위를 평균한 것
  
  - 결론 2 : 그래도 Random forests와 SVM 계열이 유의미하게 상대적으로 분류 성능이 높게 나온다. 





- 앙상블의 종류 
  
  - 동질적 앙상블 : 단일 객체 학습기를 반복적으로 사용. 
    
    - 이때 객체 학습기를 '기초 학습기'라고 하며, 
    
    - 이러한 학습 알고리즘을 '기초 학습 알고리즘'이라 부름 
  
  - 이질적 앙상블 : 서로 다른 유형의 객체 학습기 사용 
    
    - 이때 객체 학습기를 '요소 학습기' 또는 '객체 학습기'라고 부름 



---

#### Bias - Variance Decomposition

- ###### 이론적 배경
  
  - 데이터는 모델에 Noise(~Error)가 추가된 형태로 나온다 가정
    
     $y = F^*(x) + \epsilon, \epsilon$ ~ $N(0, \sigma^2)$ 
    
    > - $F^*(x)$ : Target Fuction. 위 모델을 찾으려 하지만 정확히 알 순 없다. 
    > 
    > - $\epsilon$ : 에러. 독립적이고 동일하게 분포되어있다고 가정 
  
  - 각 Dataset에 대해 $F^*(x)$ 모델을 적용하여 나온 결과를 토대로 $\hat F_i(x)$ 모델 예측 
    
     ![](./picture/4-5.png)
    
    > $\overline F(x)$ = $E[\hat F_D(x)]$ 
  
  - 특정 포인트 $x_0$에 대해서 $Err(x_0)$ 의 식을 정리하여 <mark>편차와, 분산을 분리함. </mark>
    
    ![](./picture/4-6.png)
    
    > 왜 2번째 줄에 $F^*(x_0)$가 아닌 $\hat F^*(x_0)$가 들어간거지? 동일하다고 보는건가?
    > 
    > since $E[\overline F(x_0) - \hat F(x_0)] =0,$
    
    <img src="./picture/4-7.png" title="" alt="" width="404">

- ###### 편차와 분산의 특성
  
  ![](./picture/4-8.png)
  
  - **편차(Bias) : 다양한 데이터셋으로부터 반복적으로 모델링 할 때 평균적 결과들이 유사한가?** 
    
    - Low Bias :  데이터 셋으로부터 평균적으로 정확히 측정하고 있다.
    
    - High Bias : 방향이 맞지 않다. (Poor match) 
  
  - **분산(Variance) : 개별적인 모델링이 평균과 얼마나 큰 차이를 보이는가** 
    
    - Low Variance : 다른 데이터 셋이라 하더라도 측정값이 거의 변하지 않는다. 
    
    - High Variance : 값이 퍼져 있다 (Weak match)
  
  - `Error은 원 데이터에서 부여되는 것으로 제거할 수 없다
  
  - 편차와 분산은 각각으로부터 독립적이지 않다.(Why?)

- **모델 복잡도에 따른 분류** 
  
  ![](./picture/4-10.png)
  
  - Lower model complexity : High bias & low variance 
    
    - 개별 모델링의 값의 범위는 좁으나, 평균치가 정답과 거리가 있다. 
    
    > ex) Logistic regression, LDA, k-NN with large k, etc
    
    - Bagging 방법과 잘 맞음. Bagging을 통해 분산을 줄여줄 수 있음 
  
  - Higher model complexity : low bias & high variance 
    
    - 평균치로는 정답과 가까우나, 개별 모델링의 값의 범위가 넓다. 
    
    > DT, ANN, SVM, k-NN with small k
    
    - Boosting과 잘 맞음. Boosting을 통해 편차를 줄여줄 수 있음





###### 앙상블 학습의 특징

- **목적 : 다수의 학습방식 적용을 통해 다양성을 확보하여 Error을 줄인다.** 
  
  1. 분산을 줄인다 & 데이터 다양성 확보 : Bagging 기술을 적용한다. 
  
  2. 편차를 줄인다 & 모델 다양성 확보  : Boosting 기술을 적용한다.  

- **앙상블 학습 특징** 
  
  - <mark>성능이 있으면서 일정 이상 다른 모델을 합쳤을 때(다양성을 확보할 때) 효과가 좋다.</mark> 
  
  - 따라서 앙상블 구조를 짤 때 주요 질문은 아래와 같다. 
    
    1. **충분한 다양성을 확보하기 위해 앙상블 구조의 개별 요소들을 어떻게 생성할 것인가?** (매우 중요)
    
    2. 어떻게 개별 분류기의 결과를 결합할 것인가?

- **방식** 
  
  ![](./picture/4-11.png)
  
  > 좌측 : Implicit Diversity 확보. 각 학습기에 서로 다른 Random subset을 제공한 다음, 결과값을 합침 
  > 
  > 우측 : Explicit Diversity 확보. 이전 학습 과정이 이후 과정에 영향을 미치는 등 기존 Data가 이전과 다름을 보장함. 

- **앙상블 학습이 효과가 있는 이유 (수리적 풀이)**
  
  $y_m(x)=f(x)+\epsilon_m(x)<=> E_x[(y_m(x)-f(x))^2]=E_x(\epsilon_m(x)^2)$  일 때,
  
  ![](./picture/4-13.png)
  
  - 위의 수식은 Cauchy's 부등식에 의해 항상 성립함. 
    
    > $(ax+by)^2 <= (a^2 + b^2)(x^2+y^2)$
    > 
    > - $(\epsilon_1 + ... + \epsilon_m)^2 <= (1^2 + ... + 1^2)(\epsilon_1^2 + ... + \epsilon_m^2)$
  
  - 더불어 좌측은 앙상블 Error를, 우측은 평균 Error을 의미함. 
    
    ![](./picture/4-12.png)
    
    > $f(x) = \frac{1}{M} * M *f(x)$
    > 
    > $y_m(x) - f(x) = \epsilon_m(x)$

- Error의 평균이 0이고, 각각 상관관계가 없다고 가정할 시 
  
  $E_{Ensemble} = \frac{1}{M} E_{Avg}$ 이 성립한다.  (best case)
  
      

---

#### Bagging(<mark>B</mark>ootstrap <mark>Agg</mark>regat<mark>ing</mark>)

- **방향성 / 의의** 
  
  ![](./picture/4-19.png)
  
  - 모든 앙상블의 결과값들은 서로 다른 학습 데이터로부터 만들어진다. 
  
  - 각각의 데이터 셋은 전체 N개 데이터에서 <mark>N번 랜덤 복원 추출</mark>로 만든다 **(Bootstrap)**. 
    
    - $y=f(x) + \epsilon$ 에서 원본 데이터는 $\epsilon$ 에  dependent 할 위험성이 있음. 
    
    - 따라서, Bootstrap을 통해 의도적으로 데이터의 분포를 왜곡함으로써 $\epsilon$ 이 모델과 독립적이도록 만든다. 
  
  - 각각의 데이터 셋으로 도출한 결과값을 수합하여 최종 예측 모델을 형성한다. 
  
  - 대체로 학습 모델의 성능을 향상시킨다. 
    
    ![](./picture/4-21.png)
    
    > y축이 Error rate로 낮을수록 좋음 

- **특징** 
  
  - <mark>1)OOB을 Validate Data로 사용하여 신뢰도 및 일반화 정도를 향상시킨다.  </mark>
    
    >  N번 복원 추출 간 1번도 선택되지 않는 경우 
    
    > ![](./picture/4-14.png)
    
    - 즉, N이 일정 이상 큰 수라면, $\frac{2}{3}$ 정도는 Bootsrap에 1회 이상 속하며, $\frac{1}{3}$ 정도는 한번도 안 뽑힘. 
    
    - 한번도 안 뽑히는 경우는 <mark>OOB(Out of Bag)</mark>이며, 추후 평가 데이터(Validate Data)로 사용한다. 즉, **매번 다른 데이터 셋을 통해 학습할 때 다른 평가 데이터를 사용하여 신뢰도 및 일반화의 정도를 향상시킨다.**
    
    - 그 외로 OOB는 가지치기를 도울 수도 있고, 기초 학습기가 신경망일 때는 OOB 샘플을 통해 조기 종료를 도와 과소적합 위험을 줄이는 데 도움을 줄 수 있다. 
  
  - <mark>2)모든 모델에 적용할 수 있으나, Low Bias & high variance인 모델과 잘 어울린다.</mark>
    
    ![](./picture/4-15.png)
    
    >  Ex)- ANN, SVM, DT
  
  - 3)각 데이터 셋별로 Parallel 하게 학습할 수 있어 병렬 학습이 가능한다.
  
  - 4)각 데이터 셋별 결과를 합치는 과정을 거쳐야 한다.
  
  - 5)계산 복잡도는 T(O(m) + O(s)) 로 기초 학습기의 계산 복잡도와 크게 차이 나지 않는다.(=효율적인 알고리즘이다)
    
    > O(m) : 기초 학습기 복잡도 
    > 
    > T : 훈련 횟수. 보통 그렇게 크지 않음
    > 
    > O(s) : 샘플링 및 평균 과정의 복잡도. 보통 매우 작음 
    
    

##### Result Aggregation



    <img src="./picture/4-20.png" title="" alt="" width="521">

> 수많은 결합 방식이 있으며 각 방식에 따라 결과값이 달라짐. 

- Ex -1) Majority voting. 회귀 문제에 대해서 많이 사용. 
  
  ![](file://C:\Users\PC\Desktop\TIL\Machine Learning\picture\4-16.png)

- Ex -2) Weighted voting (weight = 개별 모델의 학습 정확도)
  
  ![](file://C:\Users\PC\Desktop\TIL\Machine Learning\picture\4-17.png)
  
  > 일반적으로 훈련 데이터를 통해 가중치를 학습함. 
  > 
  > 단, 훈련 데이터가 충분치 않거나 노이즈를 많이 포함하고 있어 가중치에 대한 신뢰도가 떨어짐. 더불어 규모가 큰 경우 학습해야하는 가중치가 많아서 쉽게 과적합 문제가 발생함. 
  > 
  > 따라서, 가중 평균법이 반드시 단순 평균법보다 뛰어나다고 할 수 없음. 이에 객체 학습기의 성능 차이에 클 때 사용하며, 성능이 비슷하면 단순 평균법을 사용함.

- Ex -3) Weighted voting(weight = 각 클래스별 예상 확률)
  
  ![](file://C:\Users\PC\Desktop\TIL\Machine Learning\picture\4-18.png)
  
  > 상대다수 투표법, 가중 투표법 등 여러 버전이 있음. 
  > 
  > $P_i$가 특정 클래스로 예측하여 투표하면 Hard voting, 사후 확률에 대한 예측을 하면 Soft voting이라 함.

- Ex -4) Stacking : 메타 학습기. 각 결과를 수합하여 예측하는 새로운 예측 모델 구축
  
  ![](./picture/4-18.jpg)
  
  > 각 학습기의 훈련 세트를 그대로 메타 학습기의 훈련 세트로 사용시 과적합 위험이 커짐. 
  > 
  > 따라서 교차 검증법, 홀드 아웃 등의 방법을 통해서 초급 학습기 훈련에 사용되지 않은 샘플로 메타 학습기를 학습함

---

#### Bagging - Random Forest

- 방향성 
  
  - 결정 나무(Decision Tree) 알고리즘에 특별히 적용된 bagging 방식 
  
  - 앙상블의 다양성을 올리기 위해 DT 를 1) Bagging을 통해 다수의 Tree 생성, <mark>2) 개별 트리의 분기간 고려할 독립변수를 Randomly 선택</mark>함
    
    <img src="./picture/4-22.jpg" title="" alt="" width="407">
  
  - 이를 통해서 개별 트리의 결과의 다양성을 보다 높여줌 
    
    ![](./picture/4-23.jpg)
    
    > A의 경우가 B보다 항상 평균값은 높으나, B의 사례에서 개별 과목의 점수가 더 높은 경우가 존재한다. 
    > 
    > 따라서 샘플 뿐만 아니라, 고려하는 변수도 Randomly 하게 선택할 시 DT의 개별 결과값이 경우가 더욱 다양해진다.  
    > 
    > 일반적으로 권장하는 선택 변수의 수는 $log_2d$ 임. (d는 데이터의 차원 개수) 

- **일반화 오류**
  
  - Ramdom forest의 각 트리들은 가지치기를 적용하지 않기 때문에 과적합이 발생할 수 있다. 
  
  <img title="" src="./picture/4-27.jpg" alt="" width="579">
  
  - 랜덤 포레스트의 수렴성은 배깅과 유사하나, 초기 성능은 비교적 낮다. 하지만 객체 학습기의 숫자가 늘어남에 따라 일반적으로 더 낮은 일반화 오차율에 수렴한다. 
  
  - 만약 샘플의 개수가 충분히 크다면 일반화 오류는 아래 식에 의해 Bounded 된다. 
    
    > $Generalization$ $Error$ <= $\frac{\overline \rho(1-s^2)} {s^2}$ 
    > 
    > >  $\overline \rho $ : 개별 트리의 상관관계 계수의 평균. 다양성이 증가하면 감소한다. 
    > > 
    > > $s^2$ : margin function. (오답일 확률과 정답일 확률 차이)의 평균. 
    
    - 다양성이 증가하고, 알고리즘의 정확도가 올라갈수록 일반화 오류는 줄어든다. 
    
    ![](./picture/4-24.jpg)
    
    > 위의 예시에서의 일반화 오류는 위의 식에 따라 0.3074 보다 작거나 같다. 
    > 
    > - Average correlation value (0.9027) / Average margin (0.7460) 
  
  - 랜덤 포레스트의 훈련 효율은 배깅보다 좋다. 
    
    - 배깅은 훈련 당시 모든 속성을 고려하여 분할 속성을 선택하나, 랜덤 포레스트는 랜덤으로 의사결정트리를 사용하고 의사결정 트리는 하나의 속성 집합만을 고려하기 때문이다. 
  
  

- <mark>**Random Forest의 추가 장점 - 변수의 중요도 측정 가능**</mark>
  
  - 독립 변수 중요도 측정 방식 
    
    - 원본 데이터에 대해 OOB Error 정도를 계산
    
    - 중요도를 판단할 변수의 값을 뒤섞은(Permutation) 데이터의 OOB Error 정도를 계산
    
    - 원본 데이터와 Permutation 한 데이터 사이의 OOB Error 차이를 확인. 차이가 클수록 결정간 중요한 데이터임.
      
      <img src="./picture/4-25.jpg" title="" alt="" width="565">
      
      ![](./picture/4-26.jpg)

- Random forest에서 특정 변수의 중요도가 높다면, 
  
  - Random Permutation 전/후의 OOB Error 차이가 커야함(= $\overline d_i$ 가 커야한다 )
    
    > $d_i^m = p_i^m - e_i^m$ 
    > 
    > > $p_i$ : Permutation 한 데이터의 OBB error 
    > > 
    > > $e_i$ : 원본 데이터의 OBB error
    > 
    > $\overline d_i = \frac{1}{m} \sum_{i=1}^m d_i^m$
  
  - 각 OBB Error차이의 편차가 적어야 한다(= $s_i$가 작아야 한다)
    
    > $s_i^2 = \frac{1}{m-1} \sum_{i=1}^m (d_i^m - \overline d_i)^2$
  
  - 따라서<mark> i번째 변수의 중요도($v_i$) 는 $\frac{\overline d_i }{s_i}$</mark> 로 표현 할 수 있다. 

---
